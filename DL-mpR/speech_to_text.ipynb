{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a335c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ§ Downloading audio from YouTube...\n",
      "âœ… Audio downloaded and saved to lecture_audio.mp3\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Download audio from YouTube URL and save as MP3\n",
    "# Install yt-dlp if not already: !pip install yt-dlp\n",
    "\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "YOUTUBE_URL = \"https://www.youtube.com/watch?v=yN7ypxC7838\"  # Replace with the video URL\n",
    "OUTPUT_AUDIO_FILE = \"lecture_audio.mp3\"  # Path to save the audio\n",
    "\n",
    "# Ensure output path exists\n",
    "Path(OUTPUT_AUDIO_FILE).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download audio using yt-dlp\n",
    "print(\"ðŸŽ§ Downloading audio from YouTube...\")\n",
    "cmd = [\n",
    "    \"yt-dlp\",\n",
    "    \"-f\", \"bestaudio\",\n",
    "    \"--extract-audio\",\n",
    "    \"--audio-format\", \"mp3\",\n",
    "    \"-o\", OUTPUT_AUDIO_FILE,\n",
    "    YOUTUBE_URL\n",
    "]\n",
    "\n",
    "subprocess.run(cmd, check=True)\n",
    "print(f\"âœ… Audio downloaded and saved to {OUTPUT_AUDIO_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af34c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing audio...\n",
      "Transcription completed!\n",
      "Transcript saved to transcript.txt\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Transcribe audio to text and save to file\n",
    "# Install Whisper if not already: !pip install openai-whisper\n",
    "\n",
    "import whisper\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "AUDIO_FILE = \"lecture_audio.mp3\"  # Replace with your audio file path\n",
    "OUTPUT_TEXT_FILE = \"transcript.txt\"\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")  # You can use \"small\", \"medium\", \"large\" for better accuracy\n",
    "\n",
    "# Transcribe audio\n",
    "print(\"Transcribing audio...\")\n",
    "result = model.transcribe(AUDIO_FILE)\n",
    "transcript = result[\"text\"]\n",
    "print(\"Transcription completed!\")\n",
    "\n",
    "# Save transcript to txt file\n",
    "with open(OUTPUT_TEXT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(transcript)\n",
    "\n",
    "print(f\"Transcript saved to {OUTPUT_TEXT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b00a8e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating lecture notes with Ollama Llama 3.1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-19 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dhruv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\Dhruv\\OneDrive\\Desktop\\Astudy\\DL\\DL-mpR\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\Dhruv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Dhruv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"C:\\Users\\Dhruv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 371: character maps to <undefined>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture notes saved to lecture_notes.txt\n",
      "\n",
      "===== Preview =====\n",
      "\n",
      "Here is the transcript converted into structured lecture notes with clear sections, headings, and bullet points:\n",
      "\n",
      "**Machine Learning Models**\n",
      "\n",
      "### Overview\n",
      "\n",
      "* Machine learning models can be broadly categorized as supervised or unsupervised\n",
      "* Today's lecture will cover both types of models and their subcategories\n",
      "\n",
      "### Supervised Learning\n",
      "\n",
      "#### Definition\n",
      "\n",
      "* Involves a series of functions that maps an input to an output based on a series of example input-output pairs\n",
      "* Example: Predicting shoe size based on age using a dataset of two variables (age, shoe size)\n",
      "\n",
      "#### Subcategories\n",
      "\n",
      "* **Regression**\n",
      "\t+ Finds a target value based on independent predictors\n",
      "\t+ Output is continuous\n",
      "\t+ Examples:\n",
      "\t\t- Linear Regression: finding a line that fits the data\n",
      "\t\t- Multiple Linear Regression: finding a plane of best fit\n",
      "\t\t- Polynomial Regression: finding a curve for best fit\n",
      "* **Classification**\n",
      "\t+ Output is discrete\n",
      "\t+ Examples:\n",
      "\t\t- Logistic Regression: modeling the probability of a finite number of out ...\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Summarize transcript into lecture notes using Ollama Llama 3.1 locally\n",
    "import subprocess\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "OLLAMA_MODEL = \"llama3\"  # Your Ollama Llama 3.1 model\n",
    "TRANSCRIPT_FILE = \"transcript.txt\"  # Transcript generated in previous cell\n",
    "OUTPUT_NOTES_FILE = \"lecture_notes.txt\"\n",
    "\n",
    "# Read transcript\n",
    "with open(TRANSCRIPT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    transcript = f.read()\n",
    "\n",
    "# Prepare prompt for Ollama\n",
    "prompt = f\"\"\"\n",
    "You are an expert lecture note-taker.\n",
    "Take the following transcript and convert it into structured lecture notes with clear sections, headings, and bullet points.\n",
    "\n",
    "Transcript:\n",
    "{transcript}\n",
    "\"\"\"\n",
    "\n",
    "# Call Ollama CLI using 'run' instead of 'generate'\n",
    "print(\"Generating lecture notes with Ollama Llama 3.1...\")\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    [\"ollama\", \"run\", OLLAMA_MODEL],\n",
    "    stdin=subprocess.PIPE,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "lecture_notes, errors = process.communicate(prompt)\n",
    "\n",
    "if errors:\n",
    "    print(\"Errors:\", errors)\n",
    "\n",
    "# Save lecture notes to file\n",
    "with open(OUTPUT_NOTES_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(lecture_notes)\n",
    "\n",
    "print(f\"Lecture notes saved to {OUTPUT_NOTES_FILE}\")\n",
    "print(\"\\n===== Preview =====\\n\")\n",
    "print(lecture_notes[:1000], \"...\")  # Preview first 1000 characters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
